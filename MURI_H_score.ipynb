{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MURI_H-score.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fuG4XC39Iymd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "import time\n",
        "from collections import Counter\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "import random\n",
        "random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 8\n",
        "N_EPOCHS = 50\n",
        "LR = 1e-5\n",
        "K=50\n",
        "SAMPLES = 20000\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "3o9wXsSaA53Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mz0wa2X4uhj",
        "outputId": "a38473cb-5851-45f9-94b4-3476ae15a1e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def h_score(fx, gy):\n",
        "    fx = fx - fx.mean(0)\n",
        "    gy = gy - gy.mean(0)\n",
        "    Nsamples = fx.size(0)\n",
        "    covf = torch.matmul(fx.t(), fx) / Nsamples\n",
        "    covg = torch.matmul(gy.t(), gy) / Nsamples\n",
        "    h = -2 * torch.mean((fx * gy).sum(1)) + (covf * covg).sum()\n",
        "    return h"
      ],
      "metadata": {
        "id": "vX3uevwWI-jF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "\n",
        "        # Convolution 1\n",
        "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=8, stride=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "\n",
        "        # Max pool 1\n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=5)\n",
        "\n",
        "        # Fully connected 1 (readout)\n",
        "        # self.fc1 = nn.Linear(5184, 15)\n",
        "        self.fc1 = nn.Linear(1936, 640)\n",
        "        self.fc2 = nn.Linear(640,12)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.cnn1(x)\n",
        "        out = self.relu1(out)\n",
        "        out = self.maxpool1(out)\n",
        "        im_out = out\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc1(out)\n",
        "        out = self.sigmoid(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        return im_out, out"
      ],
      "metadata": {
        "id": "kDjniQ5oJH_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNTrainer:\n",
        "    def __init__(self) -> None:\n",
        "        self.u_frames = None\n",
        "        self.model = None\n",
        "\n",
        "    def get_dataloader(self):\n",
        "        print(\"Loading Data\")\n",
        "\n",
        "        with open('/content/drive/MyDrive/muri/dataset_list','rb') as f:\n",
        "          u_frames = pickle.load(f)\n",
        "\n",
        "        self.u_frames = u_frames\n",
        "\n",
        "        data1 = []\n",
        "        data2 = []\n",
        "        for i in range(SAMPLES):\n",
        "            data1.append(\n",
        "                np.array(\n",
        "                    # np.transpose(\n",
        "                        np.asarray(u_frames[i % len(u_frames)][random.randint(0,K-1)]) #first chooses a datapoint and then randomly selects a frame from the (K=)50 frames associated with the label\n",
        "                        # , (2, 0, 1)),\n",
        "                    # dtype=np.float32,\n",
        "                )\n",
        "            )\n",
        "            data2.append(\n",
        "                np.array(\n",
        "                    # np.transpose(                      \n",
        "                        np.asarray(u_frames[(i + 1) % len(u_frames)][random.randint(0,K-1)])\n",
        "                        # , (2, 0, 1)\n",
        "                    # ),\n",
        "                    # dtype=np.float32,\n",
        "                )\n",
        "            )\n",
        "\n",
        "        y0 = np.asarray(data1)\n",
        "        y1 = np.asarray(data2)\n",
        "\n",
        "        x = torch.from_numpy(y0)\n",
        "        y = torch.from_numpy(y1)\n",
        "        x = x.to(DEVICE)\n",
        "        y = y.to(DEVICE)\n",
        "        torch_dataset = TensorDataset(x, y)\n",
        "\n",
        "        loader = DataLoader(\n",
        "            dataset=torch_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0\n",
        "        )\n",
        "        return loader\n",
        "\n",
        "    def train_cnn(self):\n",
        "        model = CNNModel()\n",
        "        model.to(device=DEVICE)\n",
        "        data_loader = self.get_dataloader()\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "        print(\"Training Model\")\n",
        "        for epoch in range(N_EPOCHS):\n",
        "            training_loss=0.0\n",
        "            for x, y in data_loader:\n",
        "                optimizer.zero_grad()\n",
        "                x=x.unsqueeze(1)\n",
        "                y=y.unsqueeze(1)\n",
        "                # print(model(x.float())[1].squeeze(0).shape)\n",
        "                loss = h_score(model(x.float())[1], model(y.float())[1])\n",
        "                training_loss+= loss.item()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "            print(f\"Epoch [{epoch + 1}/{N_EPOCHS}], loss:{training_loss:.4f}\")\n",
        "            \n",
        "            if (epoch+1) % 2 == 0:\n",
        "\n",
        "              print(\"Saving CNN Model\")\n",
        "              torch.save(model.state_dict(), f\"new_cnn_model_{epoch+1}.pth\")\n",
        "\n",
        "        self.model = model\n",
        "        return model"
      ],
      "metadata": {
        "id": "T4RpH1AmJISR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNNTrainer().train_cnn()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFjtZyMrcWlT",
        "outputId": "5b298a81-4497-485f-fe07-cf71b70809a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Data\n",
            "Training Model\n",
            "Epoch [1/50], loss:-0.0440\n",
            "Epoch [2/50], loss:-0.0179\n",
            "Saving CNN Model\n",
            "Epoch [3/50], loss:-0.0043\n",
            "Epoch [4/50], loss:0.0076\n",
            "Saving CNN Model\n",
            "Epoch [5/50], loss:0.0009\n",
            "Epoch [6/50], loss:-0.0017\n",
            "Saving CNN Model\n",
            "Epoch [7/50], loss:-0.0007\n",
            "Epoch [8/50], loss:0.0008\n",
            "Saving CNN Model\n",
            "Epoch [9/50], loss:-0.0013\n",
            "Epoch [10/50], loss:-0.0002\n",
            "Saving CNN Model\n",
            "Epoch [11/50], loss:-0.0005\n",
            "Epoch [12/50], loss:-0.0007\n",
            "Saving CNN Model\n",
            "Epoch [13/50], loss:0.0001\n",
            "Epoch [14/50], loss:0.0002\n",
            "Saving CNN Model\n",
            "Epoch [15/50], loss:0.0001\n",
            "Epoch [16/50], loss:-0.0009\n",
            "Saving CNN Model\n",
            "Epoch [17/50], loss:-0.0014\n",
            "Epoch [18/50], loss:-0.0009\n",
            "Saving CNN Model\n",
            "Epoch [19/50], loss:-0.0002\n",
            "Epoch [20/50], loss:0.0000\n",
            "Saving CNN Model\n",
            "Epoch [21/50], loss:0.0000\n",
            "Epoch [22/50], loss:-0.0000\n",
            "Saving CNN Model\n",
            "Epoch [23/50], loss:-0.0000\n",
            "Epoch [24/50], loss:-0.0002\n",
            "Saving CNN Model\n",
            "Epoch [25/50], loss:-0.0000\n",
            "Epoch [26/50], loss:-0.0005\n",
            "Saving CNN Model\n",
            "Epoch [27/50], loss:-0.0001\n",
            "Epoch [28/50], loss:0.0004\n",
            "Saving CNN Model\n",
            "Epoch [29/50], loss:0.0000\n",
            "Epoch [30/50], loss:0.0000\n",
            "Saving CNN Model\n",
            "Epoch [31/50], loss:0.0000\n",
            "Epoch [32/50], loss:0.0000\n",
            "Saving CNN Model\n",
            "Epoch [33/50], loss:0.0000\n",
            "Epoch [34/50], loss:0.0000\n",
            "Saving CNN Model\n",
            "Epoch [35/50], loss:0.0000\n",
            "Epoch [36/50], loss:-0.0000\n",
            "Saving CNN Model\n",
            "Epoch [37/50], loss:0.0000\n",
            "Epoch [38/50], loss:-0.0000\n",
            "Saving CNN Model\n",
            "Epoch [39/50], loss:0.0000\n",
            "Epoch [40/50], loss:-0.0000\n",
            "Saving CNN Model\n",
            "Epoch [41/50], loss:-0.0000\n",
            "Epoch [42/50], loss:0.0000\n",
            "Saving CNN Model\n",
            "Epoch [43/50], loss:0.0000\n",
            "Epoch [44/50], loss:-0.0000\n",
            "Saving CNN Model\n",
            "Epoch [45/50], loss:-0.0000\n",
            "Epoch [46/50], loss:0.0000\n",
            "Saving CNN Model\n",
            "Epoch [47/50], loss:-0.0000\n",
            "Epoch [48/50], loss:-0.0000\n",
            "Saving CNN Model\n",
            "Epoch [49/50], loss:0.0000\n",
            "Epoch [50/50], loss:0.0000\n",
            "Saving CNN Model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sanity Check"
      ],
      "metadata": {
        "id": "wE0krv2jgspH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z=0\n",
        "for x, y in CNNTrainer().get_dataloader():\n",
        "  # x=x.unsqueeze(0)\n",
        "  x=x[0]\n",
        "  x=x.unsqueeze(0)\n",
        "  x=x.unsqueeze(1)\n",
        "  print(x.shape) #input\n",
        "  print(model(x.float())[1].shape) #output\n",
        "  z+=1\n",
        "\n",
        "  if z==1:\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oy5Tb5yAqt9l",
        "outputId": "3ba1d35d-f665-4739-ebd5-b2daff901959"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Data\n",
            "torch.Size([1, 1, 64, 64])\n",
            "torch.Size([1, 12])\n"
          ]
        }
      ]
    }
  ]
}